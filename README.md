### Задача 1
- Полная (аппаратная) виртуализация обеспечивает полную изоляцию и независимость виртуальных машин (ВМ) 
друг от друга благодаря использованию гипервизора - специальной программы управления и мониторинга ВМ.
ОС ВМ может не знать, что она работает внутри ВМ. Позволяет одновременно запускать на одной 
физической машине ОС и, соответственно, ПО без модификаций и даже написанное для разных аппаратных 
архитектур.
- При паравиртуализации также используется гипервизор, но при этом в гостевых ВМ
используются ОС со специально модифицированными ядрами. Благодаря этому ОС "знает", что работает внутри 
ВМ и более эффективно взаимодействует с гипервизором, что улучшает производительность ВМ, но ограничивает
выбор этих ОС.
- В контейнерной виртуализации гипервизор не используется, его роль выполняет сама хостовая ОС. При этом 
виде виртуализации ВМ наиболее легковесные и производительные, но все они используют одно ядро и одну ОС -
ту, что установлена на хостовой системе.

### Задача 2
- Высоконагруженная база данных, чувствительная к отказу - аппаратная виртуализация, как наиболее 
безопасный и защищенный от возможных сбоев тип виртуализации. Подойдет также паравиртуализация, как более 
производительное решение, но при условии, что программная среда (ОС, СУБД) хорошо поддерживают работу в 
режиме паравиртуализации.
- Различные web-приложения - виртуализация уровня ОС. Задача обычно не требует запуска различных ОС,
подавляющее большинство современных web-приложений работают так или иначе на стеке технологий на основе
Linux. Web-приложения также обычно менее чувствительны к отказу.
- Windows системы для использования бухгалтерским отделом - паравиртуализация. Windows системы лучше
запускать на Hyper-V - "родной" для них системе, отлично поддерживающую технологию паравиртуализации.
- Системы, выполняющие высокопроизводительные расчеты на GPU - виртуализация уровня ОС. Это наиболее
производительное решение, а сама задача скорее всего менее чувствительна к возможным сбоям, вычисления
всегда можно перезапустить.

### Задача 3
1. Hyper-V или vmWare vSphere - надежные, проверенные коммерческие решения от лидеров рынка виртуализации,
одинаково хорошо подходят.
Все необходимые технологии: программные балансировщики нагрузки, репликация данных, автоматизированные
механизмы создания резервных копий - имеются в обеих системах. При прочих равных, так как нет особых
требований, я бы выбрал vSphere за счет чуть лучшей поддержки Linux 
(https://www.vinchin.com/en/blog/vmware-vs-hyper-v-which-is-better-for-your-it-workloads.html, 
https://www.parallels.com/blogs/ras/hyper-v-vs-vmware/), но при ограниченном бюджете - Hyper-V, 
эта система дешевле.
2. Proxmox - open source, стабильное решение (разрабатывается с 2008г.), поддерживает Windows и Linux,
отличная производительность (основан на KVM), хорошо работает в небольших (десятки серверов) 
инфраструктурах (примеры внедрений: https://www.proxmox.com/en/proxmox-ve/testimonials), 
есть коммерческая поддержка от производителя. 
3. Hyper-V - бесплатен в варианте Hyper-V Server, максимально совместим и производителен для Windows 
инфраструктуры.
4. Docker с одной из систем оркестрации (Docker Swarm, Kubernetes) - естественно отлично работает на Linux,
создание рабочего окружения для тестирования прекрасно автоматизируется. При необходимости работать с
сильно отличающимися дистрибутивами Linux (окружение не работает на ядре хоста) придется сочетать с
паравиртуализацией на основе KVM, например, тот же Proxmox или OpenNebula.

### Задача 4
- Первое, сложно найти подходящую задачу, которая бы эффективно решалась именно с помощью
гетерогенной среды виртуализации. В мире ПО, как и в природе, идет естественный отбор, какая-то 
отдельная технология рано или поздно становится стандартом de facto, если не в отрасли в целом, 
то в отдельной большой нише. Например, сейчас KVM вытесняет Xen 
(https://datahouse.ru/articles/sistemy-virtualizacii/).
Соответственно, гетерогенная среда нужна в каких-то специфических случаях и нужно очень хорошо 
представлять себе эту специфику и понимать, что в этом случае без гетерогенной среды не обойтись.</br>
- Второе, сложно найти специалистов. Как обеспечивать работоспособность гетерогенной среды? 
Нужны или специалисты широкого профиля, хорошо разбирающиеся в нескольких системах 
виртуализации сразу или большая команда разных специалистов.</br>
- Третье, совместимость систем и сроки поддержки. Кто может гарантировать, что на долгой дистанции системы 
будут иметь возможность взаимодействовать друг с другом? Особенно при использовании коммерческих систем,
где вы никак не можете повлиять на их развитие. Есть хорошо стыкующиеся системы, например 
паравиртуализация KVM и контейнеризация Docker. А как (и зачем) стыковать KVM c vSphere или Hyper-V?</br>
- Четвертое, как следствие вышеперечисленного, гетерогенные среды оказываются дороже в эксплуатации.</br>
</br>
Если бы был выбор, конечно по возможности избегать.</br>
Как минимизировать риски? Наверное, тщательное планирование. На как можно более раннем этапе, еще до 
начала развертывания систем. Это не панацея, ошибки все равно будут допущены, но
вопрос какие - смертельные или не очень.
Например, какую систему выбрать: коммерческую или open source, а если open source, с поддержкой или без?
Коммерческие обычно быстрее в плане внедрения (Hyper-V запустить быстрее, чем Proxmox), но на
долгих дистанциях open source (по крайней мере крупные проекты) работает более стабильно, предсказуемо.</br>
Вывод - нужен опыт. Опыт работы с разными системами. Не имея опыта - невозможно осмысленно 
выбрать такую сложную вещь, как систему виртуализации. Без опыта это лотерея, шанс угадать мизерный. 
У меня опыт работы с виртуализацией (только одной системой) всего 5 лет и я пока не возьмусь выбирать 
систему для большой коммерческой компании.