# Домашнее задание к занятию «Микросервисы: принципы»

## Задача 1: API Gateway
|  | Kong | Tyk | Express Gateway | Apache APISIX | Azure API Management |
|--|------|-----|-----------------|---------------|----------------------|
| **Размещение** | Собств. инфр-а/Облако | Собств. инфр-а/Облако | Собств. инфр-а | Собств. инфр-а/Облако | Собств. инфр-а(Docker)/Облако |
| **Open Source** | Да | Да | Да | Да | Нет |
| **Технология** | Nginx, Lua | GoLang | Node.js,Express | Nginx, Lua | - |
| **Сообщество** | Большое | Среднее | Маленькое | Маленькое | Большое |
| **Конфигурация** | YAML | JSON | YAML/JSON | YAML | WebAPI/PowerShell |
| **Безопасность (аутентификация и авторизация)** | Да | Да | Да | Да | Да |
| **HTTPS** | Да | Да | Да | Да | Да |
| **Стоимость** | Бесплатно/Подписка | Бесплатно/Подписка | Бесплатно | Бесплатно | Подписка |

Я бы выбрал в качестве API Gateway Kong. Это очень популярное open-source решение, основанное на Nginx и позволяющее расширять функционал с помощью языка Lua.
Широкая поддержка сообществом, множество готовых Lua-скриптов для разных задач. Имеется возможность установки как на собственной инфраструктуре, так и в облаке.
Полностью совместимая с Kubernetes архитектура. Благодаря основе в виде Nginx обеспечивается высокая производительность, балансировка, proxy-кеширование. Поддерживается большинство популярных протоколов: REST, GraphQL, gRPC. Все возможности для автоматизации в соответствии с принципами DevOps и GitOps.</br>

Kong полностью соответствует требованиям задания:
- может маршрутизировать запросы к нужному сервису на основе конфигурации (Nginx в основе)
- возможность проверки аутентификации (Key Authentication, OAuth 2.0, LDAP, OpenID)
- обеспечивает терминацию HTTPS
</br>
</br>

## Задача 2: Брокер сообщений
|  | Kafka | RabbitMQ | Memphis | Redis |
|--|-------|----------|---------|-------|
| **Open Source** | Да (Apache 2.0) | Да (Mozilla Public) | Да (BSL 1.0) | Да (BSD) |
| **Метод доставки** | Pull | Push | Pull | Pull/Push |
| **Кластеризация** | Да | Да | Да | Да | 
| **Хранение на диске** | Да (Log) | Да (Index) | Да (Log) | Нет(In-memory) |
| **Скорость (1 queue)** | 280K msg/sec | 50K msg/sec | 300K msg/sec | 1000K msg/sec |
| **Форматы сообщений** |  |  |  |  |
| **Разделение прав** | Да | Да | Нет | Нет |
| **Простота эксплуатации** | Выше средней | Средняя | Простая | Простая |


**Форматы сообщений** Сериализация?
**Простота эксплуатации** Как измерить простоту?

Apache Kafka подходит для потоковой передачи данных без сложной маршрутизации, но с максимальной пропускной способностью. Систему выбирают, когда важны масштабируемость и доставка сообщений в правильном порядке. Например, когда вы отслеживаете активность пользователей в интернет-магазине, чтобы генерировать для них оптимальные списки товаров, рекомендуемых к покупке. 

# Домашнее задание к занятию «Микросервисы: подходы»

## Задача 1: Обеспечить разработку

Для обеспечения разработки подойдет связка GitLab и Jenkins. GitLab - для хранения кода в git, а Jenkins для CI/CD процессов.
Для обеспечения разработки подойдет GitLab - комплексное решение, как для хранения кода в git, так и для CI/CD процессов.

**Только GitLab или GitLab + Jenkins?**

Такое решение будет соответствовать всем требованиям:
- облачная система - GitLab может быть развернут как в облаке, так и на собственной инфраструктуре;
- система контроля версий Git - основная функция GitLab;
- репозиторий на каждый сервис - GitLab поддерживает неограниченное количество репозиториев, как public, так и private;
- запуск сборки по событию из системы контроля версий - GitLab CI/CD pipelines можно запускать с помощью различных триггеров, в том числе по изменению кода в git;
- запуск сборки по кнопке с указанием параметров - GitLab CI/CD pipelines можно запускать вручную с указанием переменных;
- возможность привязать настройки к каждой сборке - ?;
- возможность создания шаблонов для различных конфигураций сборок - ?;
- возможность безопасного хранения секретных данных (пароли, ключи доступа) - GitLab позволяет хранить секретные данные как внутри, так и во внешних сервисах, например HashiCorp Vault;
- несколько конфигураций для сборки из одного репозитория - ?;
- кастомные шаги при сборке - ?;
- собственные докер-образы для сборки проектов - GitLab Container Registry позволяет хранить собственные образы и собирать их них проекты;
- возможность развернуть агентов сборки на собственных серверах - GitLab Runner - приложение, которое можно установить на собственные серверы и которое будет запускать сборку проекта в соответствии с CI/CD pipeline;
- возможность параллельного запуска нескольких сборок - поддерживается GitLab;
- возможность параллельного запуска тестов - поддерживается GitLab.

## Задача 2: Логи

Для сбора логов предлагаю использовать OpenSearch (более свободный и доступный аналог ELK стека)
Проект OpenSearch управляется сообществом и лицензируется под Apache 2.0.
Как и ELK, OpenSearch содержит в себе index-based хранилище данных с возможностями поиска на основе библиотеки Apache Lucene,
компонент OpenSearch Dashboards для визуализации запросов к хранилищу, а также DataPrepper - компонент сбора данных с серверов с возможностью 
фильтрации, преобразования, нормализации и агрегирования данных

Таким образом, все условия задачи выполняются:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему - агенты DataPrepper собирают данные (логи) и отправляют их в центральное хранилище OpenSearch;
- минимальные требования к приложениям, сбор логов из stdout - агенты DataPrepper легковесны и могут быть настроены на чтение stdout приложений через стандартные pipeline ОС;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов - за это отвечает компонент OpenSearch Dashboards;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов - за это также отвечает компонент OpenSearch Dashboards;
- возможность дать ссылку на сохранённый поиск по записям логов

## Задача 3: Мониторинг

Для мониторинга подойдет стандартная связка Prometheus/Grafana.
Работает она следующим образом:
- Экспортеры собирают данные с хостов и возвращают их в виде набора метрик. 
- Prometheus получает метрики от экспортеров и сохраняет их в БД временных рядов
- Grafana отвечает за визуализацию и анализ информации

Cвязка обеспечит:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию - за это отвечает Grafana;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы - Grafana позволяет 
создавать dashboards с произвольным набором отображаемых данных.


## Домашнее задание к занятию «Микросервисы: масштабирование»

# Задача 1: Кластеризация

**K8s же, да?**

Решение должно соответствовать следующим требованиям:

    поддержка контейнеров;
    обеспечивать обнаружение сервисов и маршрутизацию запросов;
    обеспечивать возможность горизонтального масштабирования;
    обеспечивать возможность автоматического масштабирования;
    обеспечивать явное разделение ресурсов, доступных извне и внутри системы;
    обеспечивать возможность конфигурировать приложения с помощью переменных среды, в том числе с возможностью безопасного хранения чувствительных данных таких как пароли, ключи доступа, ключи шифрования и т. п.

