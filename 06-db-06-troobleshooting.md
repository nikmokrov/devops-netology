# Домашнее задание к занятию "6.6. Troubleshooting"
## Задача 1

1. С помощью команды db.currentOp() находим **opid** зависшей CRUD операции. </br> 
Например:
```console
sample> db.currentOp()
{
  inprog: [
    {
      type: 'op',
      host: 'b2fb0eede135:27017',
      desc: 'JournalFlusher',
      active: true,
      currentOpTime: '2022-12-09T11:57:50.179+00:00',
      opid: 19951,
      op: 'none',
      ns: '',
      command: {},
      numYields: 0,
      locks: {},
      waitingForLock: false,
      lockStats: {},
      waitingForFlowControl: false,
      flowControlStats: {}
    },
  ],
  ok: 1
}
```

2. С помощью команды db.killOp() останавливаем зависшую CRUD операцию
```console
sample> db.killOp(19951)
{ info: 'attempting to kill op', ok: 1 }
```

Операции Read останавливаются на всем кластере. 
Операции Write, ассоциированные с серверной сессией, можно остановить путем уничтожения
сессии командой killSessions(<lsid>) (для этого нужно предварительно найти **lsid** (logical session
id) с помощью той же db.currentOp() ), а не ассоциированные с помощью db.killOp(<opid>) 
на каждом шарде кластера.

Для решения проблемы с долгими (зависающими) запросами нужно
проанализировать, почему запрос выполняется так долго.
Техническое решение заключается в задании ограничения времени выполнения запроса 
с помощью метода maxTimeMS(). Тогда MongoDB автоматически прервет операцию, 
превысившую лимит. </br> 
Например:
```console
db.location.find( { "town": { "$regex": "(Pine Lumber)",
                              "$options": 'i' } } ).maxTimeMS(30)
```

## Задача 2
Согласно документации, Redis удаляет истекшие записи 2-мя способами:
- "ленивый" способ - удаляются записи с истекшим TTL тогда, когда истекший TTL обнаружен в момент обращения к записи;
- "активный" способ - Redis удаляет записи с истекшим TTL по адаптивному алгоритму, цикл которого запускается 10 раз в секунду. Алгоритм с настройками по-умолчанию удаляет до 200 записей в секунду и стремится к тому, чтобы количество истекших и подлежащих удалению записей не превышало 25% от общей выборки в каждом его цикле. Соответственно, если в какой-то момент
истекло большое количество ключей и их количество превышает 25% в общей выборке, это становится причиной задержек, т.к. операция удаления является блокирующей.</br>

Очевидно, что это и произошло в нашем случае. При масштабировании начался рост отношения записанных значений к истекшим, т.к. для репликации тоже требуется какое-то время, зависящее от объема базы и пропускной способности сети. В какой-то момент количество истекших значений превысило 25% от общей выборки и начались задержки.


## Задача 3
```console

```
## Задача 4
```console

```
