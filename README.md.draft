# Домашнее задание к занятию «Микросервисы: подходы»

## Задача 1: Обеспечить разработку

Для обеспечения разработки подойдет связка GitLab и Jenkins. GitLab - для хранения кода в git, а Jenkins для CI/CD процессов.
Для обеспечения разработки подойдет GitLab - комплексное решение, как для хранения кода в git, так и для CI/CD процессов.

**Только GitLab или GitLab + Jenkins?**

Такое решение будет соответствовать всем требованиям:
- облачная система - GitLab может быть развернут как в облаке, так и на собственной инфраструктуре;
- система контроля версий Git - основная функция GitLab;
- репозиторий на каждый сервис - GitLab поддерживает неограниченное количество репозиториев, как public, так и private;
- запуск сборки по событию из системы контроля версий - GitLab CI/CD pipelines можно запускать с помощью различных триггеров, в том числе по изменению кода в git;
- запуск сборки по кнопке с указанием параметров - GitLab CI/CD pipelines можно запускать вручную с указанием переменных;
- возможность привязать настройки к каждой сборке - ?;
- возможность создания шаблонов для различных конфигураций сборок - ?;
- возможность безопасного хранения секретных данных (пароли, ключи доступа) - GitLab позволяет хранить секретные данные как внутри, так и во внешних сервисах, например HashiCorp Vault;
- несколько конфигураций для сборки из одного репозитория - ?;
- кастомные шаги при сборке - ?;
- собственные докер-образы для сборки проектов - GitLab Container Registry позволяет хранить собственные образы и собирать их них проекты;
- возможность развернуть агентов сборки на собственных серверах - GitLab Runner - приложение, которое можно установить на собственные серверы и которое будет запускать сборку проекта в соответствии с CI/CD pipeline;
- возможность параллельного запуска нескольких сборок - поддерживается GitLab;
- возможность параллельного запуска тестов - поддерживается GitLab.

## Задача 2: Логи

Для сбора логов предлагаю использовать OpenSearch (более свободный и доступный аналог ELK стека)
Проект OpenSearch управляется сообществом и лицензируется под Apache 2.0.
Как и ELK, OpenSearch содержит в себе index-based хранилище данных с возможностями поиска на основе библиотеки Apache Lucene,
компонент OpenSearch Dashboards для визуализации запросов к хранилищу, а также DataPrepper - компонент сбора данных с серверов с возможностью 
фильтрации, преобразования, нормализации и агрегирования данных

Таким образом, все условия задачи выполняются:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему - агенты DataPrepper собирают данные (логи) и отправляют их в центральное хранилище OpenSearch;
- минимальные требования к приложениям, сбор логов из stdout - агенты DataPrepper легковесны и могут быть настроены на чтение stdout приложений через стандартные pipeline ОС;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов - за это отвечает компонент OpenSearch Dashboards;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов - за это также отвечает компонент OpenSearch Dashboards;
- возможность дать ссылку на сохранённый поиск по записям логов

## Задача 3: Мониторинг

Для мониторинга подойдет стандартная связка Prometheus/Grafana.
Работает она следующим образом:
- Экспортеры собирают данные с хостов и возвращают их в виде набора метрик. 
- Prometheus получает метрики от экспортеров и сохраняет их в БД временных рядов
- Grafana отвечает за визуализацию и анализ информации

Cвязка обеспечит:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию - за это отвечает Grafana;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы - Grafana позволяет 
создавать dashboards с произвольным набором отображаемых данных.



## Домашнее задание к занятию «Микросервисы: масштабирование»

# Задача 1: Кластеризация

Очевидным выбором станет Kubernetes - система оркестрации контейнеров, позволяющая автоматизировать развертывание, 
масштабирование, репликацию и мониторинг контейнерных приложений.

Решение полностью удовлетворяет всем требованиям:

- поддерживает контейнеры, разумеется, причем сразу несколько сред исполнения: Docker, containerd, CRI-O;
- умеет выполнять обнаружение сервисов с помощью DNS или переменных окружения и маршрутизацию запросов (kube-proxy);
- горизонтальное масштабирование обеспечивается службой Horizontal Pod Autoscaler (HPA), которая автоматически масштабирует количество подов,
причем показатели для масштабирования могут быть произвольными благодяря API Custom Metrics;
- автоматическое масштабирование кластера (Cluster Autoscaler) позволяет постепенно увеличивать или уменьшать число узлов в группе 
(до указанного максимального и минимального размера) в зависимости от нагрузки на кластер;
- явное разделение ресурсов, доступных извне и внутри системы, обеспечивается при помощи пространств имён (namespaces);
- возможность конфигурировать приложения с помощью переменных среды имеется, в том числе в переменные среды можно
 передавать чувствительные данные (пароли, ключи доступа, ключи шифрования) из специального ресурса - Kubernetes Secrets

 В качестве альтернативы Kubernetes можно рассмотреть систему HashiCorp Nomad. Nomad более универсален за счет поддержки не только контейнеризованных
 приложений (поддерживаются микросервисные и пакетные приложения, включая Docker, Java, Qemu и др.). Nomad проще в развертывании, он доступен как в виде
 бинарного файла, так и в виде готовых пакетов для различных операционных систем, а также может быть собран из исходников. Nomad поддерживает большее
 число узлов и контейнеров в кластере, и в целом несколько производительнее. В Nomad имеется и горизонтальное и автомасштабирование кластера, а также
 поддерживаются namespaces. К недостаткам Nomad можно отнести отсутствие встроенной возможности обнаружения сервисов, для этого необходимо использовать 
 связку с Consul, а также он проигрывает в плане безопасности, для хранения чувствительных данных придется использовать стороннюю систему Vault.

 # Задача 2: Распределённый кеш